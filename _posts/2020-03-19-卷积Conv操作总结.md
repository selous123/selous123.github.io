---
title: 卷积操作说明
date:  2020-03-19 13:34:13 +0800
category: computer-vision
tags: deep-learning convolution
excerpt: 详细介绍神经网络中的卷积操作(a)——持续更新
comment: True
mathjax: True
---

卷积作为神经网络中最基础的模块，其重要性也是不言而喻的。其作用相当于学习到特定的卷积核 filter 通过卷积操作提取到输入的特定的特征，然后利用这些特征去做接下来的任务。下面我们详细介绍卷积操作的过程。


博客动图来源：https://github.com/vdumoulin/conv_arithmetic

### 1. 卷积操作

**基本卷积操作**： 假设输入和卷积核为：

$$
x = \left(
    \begin{aligned}
    3,3,2,1,0 \\
    0,0,1,3,1 \\
    3,1,2,2,3 \\
    2,0,0,2,2 \\
    2,0,0,0,1
    \end{aligned}
    \right) \in\mathcal{R}^{5 \times 5}; \quad
\text{kernel} = \left(
    \begin{aligned}
    0,1,2 \\
    2,2,0 \\
    0,1,2
    \end{aligned}
    \right) \in\mathcal{R}^{3 \times 3}
$$

则输出$o = x \otimes \text{kernel} \in \mathcal{R}^{3\times 3}$; 则基本卷积过程如下图所示为：


<center><img src="https://selous123.github.io/assets/img/blog-conv/conv.gif" width="60%" height="auto"/>

<span>图1. 卷积操作示意图.</span></center>

<font color="blue">缺点：从上述卷积操作的结果可以发现 $5 \times 5$ 的特征图谱 $x$ 经过 $3 \times 3$ 的卷积操作后，输出结果为 $3 \times 3$ 的特征 $o$。</font> 在实际应用中，特征图谱会随着卷积层数的增加而不断减小。这样的情况是不利于深度网络的。
其中输入和输出之间的大小关系为：

$$
\text{O}_\text{shape} = \text{I}_\text{shape} - \text{kernel\_size} + 1
$$

**Padding操作**： 所以基于上述操作我们就会在输入特征 $x$ 四周填充 0 元素，保证输入和输出大小不变。如下为 $\text{Padding} = 1$ 的操作示意图：

<center><img src="https://selous123.github.io/assets/img/blog-conv/padding.gif" width="60%" height="auto"/>

<span>图2. Padding操作示意图.</span></center>

数学公式为：

$$
\text{O}_\text{shape} = \text{I}_\text{shape} - \text{kernel\_size} + 2 * \text{Padding} + 1
$$

<font color="red">此时卷积操作输出的大小和原始特征图谱大小相同。常见 $\text{kernel}\_\text{size}$ 和 $\text{padding}$ 组合为：$(3,1),(5,2),(7,3)$ </font>

**Stride步长操作**：
步长参数表示卷积核每次移动的距离，默认步长为1。具体操作如下图所示：

<center><img src="https://selous123.github.io/assets/img/blog-conv/p.gif" width="60%" height="auto"/>

<span>图3. stride参数操作示意图.</span></center>

输入输出的数学公式表达为：

$$
\text{O}_\text{shape} = \lceil\frac{\text{I}_\text{shape} - \text{kernel\_size} + 2 * \text{Padding} + 1}{\text{stride}}\rceil
$$


### 2. 卷积操作参数量和计算量

<center><img src="https://selous123.github.io/assets/img/blog-conv/conv.png" width="80%" height="auto"/>

<span>图3. 卷积层操作示意图.</span></center>

所以卷积操作的参数量为：

$$
\text{Params} = C_\text{in} * C_\text{out} * K * K 
$$

卷积操作的计算量（Flops）为：

$$
\begin{aligned}
\text{Flops}_\text{mul} &= C_\text{in} *  K * K * H_\text{out} * W_\text{out} * C_\text{out} \\
\text{Flops}_\text{add} &= (C_\text{in} * K * K - 1) * H_\text{out} * W_\text{out} * C_\text{out} \\
\end{aligned}
$$

### 3. 卷积操作感受野计算

1. 最后一层（卷积层或池化层）输出特征图感受野的大小等于卷积核的大小。

2. 第i层卷积层的感受野大小和第i层的卷积核大小和步长有关系，同时也与第（i+1）层感受野大小有关。

3. 计算感受野的大小时忽略了图像边缘的影响，即不考虑padding的大小。

关于感受野大小的计算是自下向上计算，计算公式为：

$$
\text{RF}_i = ( \text{RF}_{i+1} - 1 ) * \text{stride} + \text{ksize}_i
$$


示例如图所示：
<center><img src="https://selous123.github.io/assets/img/blog-conv/effective_field.png" width="70%" height="auto"/>

<span>图. 卷积感受野示意图.</span></center>


### 4. 空洞卷积 (Dilated convolution)

<center><img src="https://selous123.github.io/assets/img/blog-conv/dilation.gif" width="60%" height="auto"/>

<span>图. 空洞卷积操作示意图.</span></center>

### 5. 装置卷积 (transpose convolution)

<center><img src="https://selous123.github.io/assets/img/blog-conv/no_padding_strides_transposed.gif" width="60%" height="auto"/>

<span>图. 反转卷积（逆卷积）操作示意图.</span></center>


### 6. Group 分组卷积

<center><img src="https://selous123.github.io/assets/img/blog-conv/gconv.png" width="90%" height="auto"/>

<span>图. group卷积操作示意图.</span></center>

Group卷积参数量：

$$
\begin{aligned}
\text{Params} &= K * K * \frac{C_\text{in}}{G} * C_\text{out} \\
\text{Flops} &= K * K * \frac{C_\text{in}}{G} * \frac{C_\text{out}}{G} * H * W * G
\end{aligned}
$$

故 分组卷积的的参数量 $\text{Params}$ 和 计算量 $\text{Flops}$ 都是原始卷积的 $\frac{1}{G}$。


**当分组卷积中参数 $G$ 取值为 $C_\text{in}$ 时， 分组卷积就成为了 Xception 结构中 的depth-wise convolution。**

<font color="blue">但是这种卷积方式输出的特征图谱，只和对应的特征图谱有关，输出特征图中所包含的信息太少。</font> 所以一般会加一个point-wise convolution。如图所示。

<center><img src="https://selous123.github.io/assets/img/blog-conv/xception.png" width="90%" height="auto"/>

<span>图. Xception卷积操作示意图.</span></center>


$$
\begin{aligned}
\text{Params} &= K * K * 1  * C_\text{in} + 1 * 1 * C_\text{in} * C_\text{out} \\
\text{Flops} &= K * K * 1 * C_\text{in} *  H_\text{out} * W_\text{out} + C_\text{in} * 1 * 1 * H_\text{out} * W_\text{out} * C_\text{out}
\end{aligned}
$$


#### 7. 可形变卷积

变形卷积单元中增加的偏移量是网络结构中的一部分，通过另外一个平行的标准卷积单元计算得到，进而也可以通过反向传播进行端到端的学习。加上该偏移量学习之后，可变形卷积核的大小和位置可以根据当前需要识别的图像内容进行动态调整，其直观效果就是不同位置的卷积核采样点位置会根据图像内容发生自适应的变化，从而适应不同物体的形状、大小等几何形变。


<center><img src="https://selous123.github.io/assets/img/blog-conv/deformconv.png" width="70%" height="auto"/>

<span>图. Xception卷积操作示意图.</span></center>

对于 $3 \times 3$ 的卷积核来说，常规卷积方式为：

$$
\begin{aligned}
\mathcal{R} &= \{(-1,-1),(-1,0),\cdots,(1,1)\} \in \mathbb{R}^{3 \times 3} \\
y(p_0) &= \sum_{p_n\in\mathcal{R}} w(p_n) * x (p_0 + p_n)
\end{aligned}
$$

假设上述学到的 偏移量为 $\{\Delta p_n| n = 1, \cdots, N\}$，其中 $N = \|\mathcal{R}\|$ 则可形变卷积的表达式为:

$$
y(p_0) = \sum_{p_n \in \mathcal{R}} w(p_n) * x(p_0+p_n+\Delta p_n)
$$


<font color="red"> 可形变卷积的自适应感受野：</font>



<center><img src="https://selous123.github.io/assets/img/blog-conv/receptive_field.png" width="70%" height="auto"/>

<span>图. 普通卷积和可形变卷积的感受比较.</span></center>


<center><font size="5"> <b> Reference </b> </font></center>

[1]. Dai, Jifeng, et al. "Deformable convolutional networks." ICCV 2017.