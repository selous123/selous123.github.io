---
title: 深度学习及常用优化器总结
date:  2020-03-13 20:28:13 +0800
category: deep-learning
tags: deep-learning optimizer
excerpt: 深度学习基础-介绍常用优化器
mathjax: true
comment: true
---

### 1. 基础数学知识

#### 1.1. 指数加权平均(滑动平均)
函数定义如下：

$$v_t = \beta * v_{t-1} + (1-\beta) * \theta_t$$
其中$\beta$的值一般令为0.9

通过数学迭代:

$$v_t = \sum_{i=0}^t ((1-\beta)*\beta^{t-i}) \theta_i$$

我们可以发现当 $t \gg i = t_i$ 时 $\beta^{t-t_i}$ 趋向于 $0$, 于是 $v_t$ 可以近似为 第$(t-t_i) \sim t$ 的 $\theta$ 求加权平均。

更具体来说，当$\beta = 0.9$时， 
$$v_t = 0.1 \theta_t + 0.1 * 0.9^1 \theta_{t-1} + 0.1 * 0.9^2 \theta_{t-2} + ...$$

我们可以认为 $v_t$ 近似于 后$\frac{1}{1-\beta} = 10$ 个$\theta$的平均值 (滑动平均 )，表达式如下:

$$v_t \approx E_{i=t-9}^t[\theta_i]$$

<font color='red'>优点：可以忽略较久远的数据对当前数据的影响</font>

#### 1.2. 偏差修正
对于上述迭代，我们令$v_0 = 0$, $\beta = 0.9$ 则：

$$
\begin{aligned}
v_1 &= \beta v_0 + (1 - \beta)\theta_1 = 0.1 \theta_1 \\
v_2 &= \beta v_1 + (1 - \beta)\theta_2 = 0.1 \theta_2 + 0.09 \theta_1 \\
v_3 &= 0.1 \theta_3 + 0.09\theta_2 + 0.081\theta_3\\
...
\end{aligned}
$$
上述迭代关系可以发现，当迭代轮次靠前的时候，计算值要比真实梯度小很多，所以我们用下面的表达式进行修正。

$$v_t = \frac{v_t}{1-\beta^t}$$

其中$\lim_{t->\infty}\beta^t = 0$，也就是随着迭代次数 $t$ 的增大，偏差修正系数$\frac{1}{1-\beta^t}$ 会逐渐变小，趋向于0。<font color="red"> 偏差修正对迭代前期影响比较大，而后期可以忽略不计。 </font>

### 2. 常用优化器总结
在机器学习的框架中，我们学习的目的就是能找到一个映射 $f$ 的所有参数 $\Theta$, 使得输入 $x$ 通过这个映射能获得我们预期的标签 $y$。我们首先会通过定义损失函数 $J(\Theta|x,y)$, 1) 如果该损失函数有最小值，那么直接通过数值计算计算出对应的 $\Theta$； 2) 如果不存在最小值，那么我们就需要通过迭代的找到更优的解，这就需要优化器的存在。深度学习最常用的优化器思想时基于梯度下降，因为数学中的梯度概念表明：**对于函数 $J$, 其函数值下降最快的方向是负梯度方向**。所以我们首先初始话 $\Theta_0$, 然后根据数据的梯度迭代更新 $\Theta$. 数学是表达为：

$$\hat{\Theta} = \min_\theta J(\Theta| x, y)$$

其中:

$$
\begin{aligned}
\Theta_0; \Theta_{t+1} &= \Theta_t - \eta * \frac{dJ(\Theta|x, y)}{d\Theta_t} \\
&=\Theta_t - \eta * \nabla_{\Theta_t} J(\Theta_t)
\end{aligned}
$$

对于优化器的主要改进就在于如何计算损失函数的梯度。
#### 2.1. BGD & SGD & MSGD
**这三种梯度下降方法的区别在于一次选定多少个样本来计算损失函数的梯度。这样的话自然就涉及到一个 trade-off，即参数更新的准确率和运行时间。**

a) BGD (Batch Gradient Descend)
用整个数据集计算整体损失，然后求导更新：

$$\theta =\theta - \eta * \nabla_{\theta} J(\theta)$$

<font color="blue">缺点：由于这种方法是在一次更新中，就对整个数据集计算梯度，所以计算起来非常慢，遇到很大量的数据集也会非常棘手，而且不能投入新数据实时更新模型。</font>

b) SGD (Stochastic Gradient Descent)
与 BGD 每次对整个数据集样本更新不同的是，SGD对每一个样本都进行一次梯度更新：

$$\theta = \theta - \eta * \nabla_{\theta} J(\theta|x^i,y^i)$$

<font color="blue">缺点：因为更新比较频繁，会造成 cost function 有严重的震荡。但是SGD和BGD的收敛性是一样的。而且由于SGD有震荡，所以SGD可能会比BGD收敛到更好的局部极小值点。</font>

c) MBGD (Mini-Batch Gradient Descend)
结合上述两种的优点，我们可以每次利用一小部分（mini-batch）样本进行梯度更新，<font color="red">既可以减少参数更新时候的方差，减少振荡，也可以保证有较快的更新速度。</font>：
$$\theta = \theta - \eta * \nabla_{\theta} J(\theta|x^{(i:i+m)},y^{(i:i+m)})$$

<font color="blue">
共同的缺点：

1. 这些方法容易陷入局部极小值点和鞍点，不能保证收敛性

2. 对于所有的样本都使用相同的学习率 $\eta$。但是如果我们的数据是稀疏的，那我们希望出现频率小的可以获得大一点的更新，反之亦然。
</font>

#### 2.2. 基于动量 (Momentum) 的改进
a). Momentum

通过加入动量 $\gamma v_{t-1}$, 也就是梯度的历史信息，<font color="red">可以使得梯度方向不变的维度上速度变快，梯度方向有所改变的维度上的更新速度变慢，这样就可以加快收敛并减小震荡。</font>

$$
\begin{aligned}
v_t &= \gamma v_{t-1} + \eta\nabla_\theta J(\theta) \\
\theta_t & \leftarrow \theta_{t} - v_t
\end{aligned}
$$
其中超参数$\gamma$ 一般设定为0.9。

<font color="blue">
缺点：这种情况相当于小球从山上滚下来时是在盲目地沿着坡滚，如果它能具备一些先知，例如快要上坡时，就知道需要减速了的话，适应性会更好。
</font>

b). NAG (Nesterov Accelerated Gradient)

基于Momentum的缺点进行改进，直接计算未来位置的梯度（先知），然后进行梯度更新：

$$
\begin{aligned}
v_t &= \gamma v_{t-1} + \eta\nabla_\theta J(\theta - \underline{\gamma v_{t-1}}) \\
\theta_t & \leftarrow \theta_{t} - v_t
\end{aligned}
$$

上述的改进都是在更新梯度时顺应 $J$ 函数的梯度来调整速度，并且对 SGD 进行加速。
<font color="blue">缺点：上述的方法都没有考虑到不同参数的重要性，我们希望能根据不同的参数的重要性而设置不同参数的更新程度。</font>

#### 2.3 基于参数重要性的改进
a) AdaGrad (Adaptive gradient algorithm)

<font color="red">这个算法就可以对低频的参数做较大的更新，对高频的做较小的更新，也因此，对于稀疏的数据它的表现很好，很好地提高了 SGD 的鲁棒性。</font>

$$
\begin{aligned}
v_{t,i} = \frac{\eta}{\sqrt{G_{t,i} - \epsilon}} \nabla_{\theta_i} J(\theta) \\
\theta_{t+1,i} = \theta_{t,i} - v_{t,i}
\end{aligned}
$$

其中 $G_{t, i}$ 是一个对角矩阵, 元素 $i$ 为 $t$ 时刻参数 $θ_i$ 的梯度平方和，也就是 $G_{t, i} = \sum_{j=0}^t\nabla\theta_{j,i}^2$

<font color="blue">缺点：分母 $G_{t, i}$ 会随着迭代次数不断积累，这样学习率就会收缩并最终会变得非常小。</font>

b) RMSprop 

基于上述AdaGrad的累计求和会导致学习率骤降的缺点，Hinton引入指数加权平均的思想，来计算梯度累计量$G_{t,i}$

$$
G_{t,i} = \beta G_{t-1,i} + (1 - \beta) \nabla\theta_{t,i}^2
$$

一般的设 $\beta = 0.9$。<font color="red">通过之间的指数加权我们可以知道，对于 梯度累积量 $G_{t,i}$ 可以近似于后10项梯度的平方平均，所以就避免了AdaGrad中的学习率骤降的缺点。</font>

c) Adadelta

该工作的是基于AdaGrad的改进，首先关于 梯度累计量 $G$ 值的计算与上述RMSprop相同，而对于学习率 $\eta$, 文中提出可以 **通过前(t-1)时刻的梯度平方的滑动平均值** 代替学习率，设置 $\eta$ 为:

$$
\begin{aligned}
\eta &= v_{t-1} \\
v_{t} &= \beta v_{t - 1} + (1-\beta)\nabla \theta_{t}^2
\end{aligned}
$$

**【需要数学证明，说明学习率可以这样设置！】**

#### 2.4 Adam (Adaptive Moment Estimation)
这个算法是另一种计算每个参数的自适应学习率的方法。相当于 RMSprop + Momentum

首先像Momentum方法一样，计算一阶梯度信息的指数衰减平均值：

$$m_t = \beta_1 m_{t-1} + (1-\beta_1) \nabla\theta_t$$

然后像RMSprop方法一样， 计算平方梯度信息的指数衰减平均值：

$$v_t = \beta_2 v_{t-1} + (1-\beta_2) \nabla\theta_t^2$$

而且对于$m_t$ 和 $v_t$ 在更新前会做偏差修正：

$$
\begin{aligned}
\hat{m} = \frac{m}{1-\beta_1} \\
\hat{v} = \frac{v}{1-\beta_2}
\end{aligned}
$$

然后进行梯度更新：

$$\theta_{t+1} = \theta_t - \frac{\eta}{\sqrt{\hat{v}_t+\epsilon}} \hat{m}_t $$

建议 $\beta_1 ＝ 0.9，\beta_2 ＝ 0.999，\epsilon ＝ 10^{−8}$

<font color="red">实践表明，Adam 比其他适应性学习方法效果要好。</font>

### 3. 常见问题
1). 证明负梯度方向，是函数下降最快的方向？

**泰勒展开**：
函数 $f(x)$ 在 $x=x_0$ 处的泰勒展开为

$$
\begin{aligned}
f(x) &= \sum_{i=0}^n \frac{f^{(i)}(x_0)}{i!}(x-x_0)^i \\
&=f(x_0) + \frac{1}{1}f'(x_0)(x-x_0) +...+\frac{1}{n!}f^{(n)}(x_0)(x-x_0)^n
\end{aligned}
$$

于是

$$
f(x+v) = f(x) + f'(x)*v + \epsilon
$$

其中 $f'(x)$ 和 $v$ 均为矢量，于是$f'(x)*v = |f'(x)||v|cos\theta$, 则当矢量 $v$ 的方向与导数方向共线时，该值最大。于是负梯度方向，即为函数下降最快的方向


2). 如何选择优化算法
如果数据是稀疏的，就用自适用方法，即 Adagrad, Adadelta, RMSprop, Adam。
RMSprop, Adadelta, Adam 在很多情况下的效果是相似的。
Adam 就是在 RMSprop 的基础上加了 bias-correction 和 momentum，
随着梯度变的稀疏，Adam 比 RMSprop 效果会好。
整体来讲，Adam 是最好的选择。
很多论文里都会用 SGD，没有 momentum 等。SGD 虽然能达到极小值，但是比其它算法用的时间长，而且可能会被困在鞍点。
如果需要更快的收敛，或者是训练更深更复杂的神经网络，需要用一种自适应的算法。


<center> <font size="5"><b>Reference</b></font> </center>

博客：https://www.cnblogs.com/guoyaohua/p/8542554.html