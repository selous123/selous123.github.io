---
title: 图像超分辨率工作总结.
date:  2020-03-14 10:12:13 +0800
category: computer-vision
tags: deep-learning super-resolution
excerpt: 超分辨率模型
comment: True
mathjax: True
---

图像超分辨率：该任务是通过硬件或软件的方法提高原有图像的分辨率，通过低分辨率的图像来得到高分辨率的图像过程就是超分辨率重建。

**超分辨率任务的数学表示**：

$$
\begin{aligned}
Y &= D_{RV}(X) \\ &= H \oplus X + \epsilon
\end{aligned}
$$

假设 $X$ 为原始高分辨率图像，由于采像设备/环境的问题，我们只能够采集到低分图像 $Y$。 超分的任务就是根据低分辨率 $Y$，构造重建函数 $f$, 使得重建结果 $f(Y)$ 逼近于高分辨率图像 $X$。其中 $H$ 是图像真实的降采样模糊核，$\epsilon$ 是环境中的高斯噪声。

## 传统超分辨率算法

在传统的[超分辨率算法](https://arxiv.org/pdf/1904.07523.pdf)中, 损失函数定义为：

$$J(x) = \underbrace{L(y, H \oplus x)}_{data \quad term} + \alpha * \underbrace{\Psi(H, x)}_{regularizer}$$

最小化损失函数$J(x)$得到最终的重建结果：

$$\hat{x} = \arg_x\min J(x)$$

传统超分辨率的工作的主要改进点位于如何设计一个符合人为直观的正则项 $\Psi(H, x)$, 然后设计优化算法优化损失函数 $J(x)$，得到最终的重建结果 $\hat{x}$

**从SRCNN开始，深度学习算法被应用到图像超分领域。得益于大量数据的使用和深度模型强大的拟合能力，深度网络在超分领域的表现要优于传统基于正则的的超分辨率工作。**

## 2. Deep Learning for SR

#### 2.1. 如何获取大量的训练数据：
对于有监督的神经网络训练来说，我们需要获得大量的低分和超分的图像对，作为训练数据。但是在真实场景中，我们很难同时采集到同一个场景的成对图像。所以基于深度学习的方法，都是基于合成的图像退化模型，比如bicubic插值下采样等，构造训练集的过程如下图所示：

<center><img src="https://selous123.github.io/assets/img/blog-surveySR/training_pairs.png" width="500" height="auto"/>

<span>图. 如何通过合成算法构建训练数据对.</span></center>

#### 2.2. 基于深度模型的改进工作

<center><img src="https://selous123.github.io/assets/img/blog-surveySR/survey_for_sr.png" width="80%" height="auto"/>

<span>图. 图像超分辨率工作预览.</span></center>


##### a) 网络架构 (Network Architecture)

<center><img src="https://selous123.github.io/assets/img/blog-surveySR/network_architecture.png" width="60%" height="auto"/>

<span>图. 图像超分辨率架构设计预览.</span></center>

##### b) 损失函数 (Loss Function)
b.1). Pixel 损失

$$
\begin{aligned}
L_1(\hat{I},I) &= \frac{1}{hwc} \sum_{ijk} ||\hat{I}_{ijk} - I_{ijk}||_1 \\
L_2(\hat{I},I)&=\frac{1}{hwc} \sum_{ijk} ||\hat{I}_{ijk} - I_{ijk}||_2
\end{aligned}
$$

$L_1$ 和 $L_2$ 损失的比较： <font color='red'>与L1损失相比，L2损失会惩罚较大的误差，但更能容忍较小的误差，因此通常会导致结果过于平滑。 实际上，L1损耗显示出比L2损耗更高的性能和收敛性**</font>

b.2). Content 损失
通过提取预训练模型在图像对的特征，计算特征之间的距离。

$$
L_{content}^l(\hat{I},I) = \frac{1}{h_lw_lc_l}\sqrt{\sum_{ijk}(\phi^l_{ijk}(\hat{I}) - \phi^l_{ijk}(I))^2}
$$

其中 $\phi$ 为预训练深度模型，$l$ 为第 $l$ 层。

b.3). Texture 损失

图像的纹理定义为图像特征图不同channel之间的关系矩阵，我们用矩阵内积定义特征图谱之间的关系。

$$
G_{ij}^{(l)}(I) = vec(\phi_i^{l}(I)) * vec(\phi_j^{l}(I))
$$

然后定义纹理损失为：

$$
L_{texture}(\hat{I}, I) = \frac{1}{c_l^2}\sqrt{\sum_{ij}(G_{ij}^l(\hat{I}) - G_{ij}^l(I))^2}
$$

纹理损失的引入可以使得生成的图像包含丰富的纹理特征。

b.4). Adversarial 损失
<font color="red">通过引入GAN的判别器，判别生成分布和原始图像分布之间的距离</font>

b.5). Cycle Consistency 损失
b.6). Total Variance 损失
TV损失的约束图像在$x$和$y$方向上的梯度，约束生成图像足够光滑。

$$
L_{TV}(\hat{I}) = \frac{1}{hwc}\sum_{ijk}\sqrt{(\hat{I}_{i, y+1, k} - \hat{I}_{i, y, k})^2 + (\hat{I}_{i+1, y, k} - \hat{I}_{i, y, k})^2}
$$

b.7). Prior-Based 损失
##### c) 评价指标 (Image Quality Assessment)
c.1). PSNR
c.2). SSIM
c.3). Mean Opinion Score
c.4). Learning-based Perceptual Quality

虽然主观指标捕捉人类视觉感知方面表现出更好的性能，但我们需要什么样的感知质量（例如，更真实的图像，或与原始图像的一致性）仍然是一个有待探索的问题。 所以客观IQA方法（如PSNR、SSIM）仍是目前的主流。


## 3. 当前存在的问题

1. 基于合成退化训练出来的模型，很难在真实的数据上有很好的表现。

2. PSNR指标的问题，指标高并不代表生成的图像人眼看起来好。

3. 真实应用中，图像变焦的倍数是不固定的，固定变焦所训练的模型在这种应用场景下无法使用。


## 4. 常见问题

#### 1) 为什么从EDSR模型开始，超分基础模块中不再使用BN做归一化？



<center> <font size="5"><b>Reference</b></font> </center>

[1]. Deep Learning for Image Super-resolution:
A Survey