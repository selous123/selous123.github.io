---
title: Frame-recurrent Video Denoise with Optical Flow for Alignment
date:  2020-03-14 10:12:13 +0800
category: computer-vision personal-project
tags: deep-learning denoise
excerpt: 去噪模型
comment: True
mathjax: True
---


此代码是从[EDSR pytorch](https://github.com/thstkdgus35/EDSR-PyTorch)github存储库中修改的，用于视频去噪。

该方法改编自CVPR2018论文: [Frame-Recurrent Video Super-Resolution](https://arxiv.org/abs/1801.04590)


我们称之为Frame-Recurrent Video Denoising (FRVD)

项目github地址：https://github.com/selous123/denosing-pytorch

### 1. 网络架构
1). 深度去噪项目要求：

a. 模型在在线视频流（当前帧去噪时只能考虑前帧序列的信息）的去噪任务上的表现 , 如PSNR指标

b. 模型在视频序列前后帧中的去噪效果不要出现很大的跳跃（大的效果跳跃会使得在真实应用中造成不好的用户体验）

2). 解决思路：

a. 引入RNN 模型，考虑前帧的信息.

b. 引入光流对齐模块，对齐前后帧，以防大的移动导致模型性能下降

**网络的整体框架如下**：首先通过计算带噪视频两帧$(I_{t-1}, I_t)$之间的光流图 $F$，然后将光流图 $F$ 作用在前帧的预测结果 $I_{t-1}^{est}$中得到 $\hat{I}_{t-1}^{est}$，然后与$I_t$一起输入到去噪网络中得到去噪结果。
<center><img src="https://raw.githubusercontent.com/selous123/denosing-pytorch/master/structure.png" width="500" height="auto"/>

<span>Fig 1. The recurrent module for Frame Recurrent Video Denoising (FRVD)</span></center>

### 2. 光流预测模型

我们基于 [AAAI 2018 paper](https://pdfs.semanticscholar.org/47bc/34ae6f5dc104bc289ae3bb4fa75ef75fbc21.pdf)的工作，提出一个新的处理带噪数据的光流预测模型。
**改进思路：** 在光流网络中集成去噪模块，提高光流任务的表现。
**初始方案：** 在光流网络前集成一个预去噪模块。

下面我们首先介绍AAAI 2018的无监督光流预测网络的工作以及模型在带噪数据上的问题，然后给出我们提出改进的去噪光流网络的结果。
#### 2.1. 无监督光流预测网络
##### a). 网络架构

<center><img src="https://raw.githubusercontent.com/selous123/denosing-pytorch/master/show/of/architecture.png" width="500" height="auto"/>
</center>

#### b). 损失函数
**Multi-scale Warped Loss:**

$$L_{data} = \sum_{i=1}^6 weight_i * L_1(warp(F_i^{\uparrow}, Frame1), Frame2)$$

**Smoothness Regularization Loss:**

$$L_{reg} = \sum_{i=1}^6weight_i * TVL_1(F_i)$$

**Hybrid Loss:**

$$L = L_{data} + \lambda * L_{reg}$$

#### c). 实验结果


c.1). 不带噪数据情况下
<center><img src="https://raw.githubusercontent.com/selous123/denosing-pytorch/master/show/of/psnr.png" width="500" height="auto"/>

<span>Fig. PSNR of validation set on clean data.</span></center>
<center><img src="https://raw.githubusercontent.com/selous123/denosing-pytorch/master/show/of/of.png" width="500" height="auto"/>

<span>Fig. Aligned results of validation set on clean data.</span></center>

c.2). 带噪数据情况下
<center><img src="https://raw.githubusercontent.com/selous123/denosing-pytorch/master/show/of/psnr_noise.png" width="500" height="auto"/>

<span>Fig. PSNR of validation set on noised data.</span></center>
<center><img src="https://raw.githubusercontent.com/selous123/denosing-pytorch/master/show/of/of_noise.png" width="500" height="auto"/>

<span>Fig. Aligned results of validation set on noised data.</span></center>

#### 2.2. 集成带噪模块后的光流预测结果

实际效果：集成去噪模块后的光流预测图基本无噪点，对齐效果远好于原始模型

结果未上传到github，等待更新中。。

### 3. 整体模型(FRVD)的表现
我们将改进后的flownet模块集成到去噪框架中，如图1所示。
我们可以通过模型得到满足时间连续性去噪结果。我们还将测试结果制作成视频文件，以便更清楚地观察。

**在vimeo数据集上：**
<center><video src="https://raw.githubusercontent.com/selous123/denosing-pytorch/master/show/frvdwof/vimeo_presentation.mp4" controls="controls" width="70%" height="auto">
你的浏览器不支持HTML5浏览器
</video>
</center>

**在ToFlow测试集上：**
<center><video src="https://raw.githubusercontent.com/selous123/denosing-pytorch/master/show/frvdwof/ToFlowTest_presentation.mp4" controls="controls" width="70%" height="auto">
你的浏览器不支持HTML5浏览器
</video>
</center>


### 4. 改进思路
a). RNN模型只能考虑前一帧的信息，所以设计网络融合前n帧的信息。


Enjoy Myself!
